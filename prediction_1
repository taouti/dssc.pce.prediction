import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Constants
constants = {
    "Ha_kcalPermol": 627.51,
    "Ha_eV": 27.2114,
    "KB": 1.380649e-23,
    "viscosityHe": 20.0e-6,
    "densityHe": 9.00e-2,
    "NA": 6.022e23,
    "T": 300,
    "ECB_TiO2": -4.00,
    "Eredox_iodide": -4.80,
}

# Step 1: Load the Dataset
input_file = "dyes_data_PBE_1.xlsx"  # Replace with your actual file path
data = pd.read_excel(input_file)

# Validate required columns
required_columns = [
    'E_HOMO', 'E_LUMO', 'oscillator_strength', 'mass', 'expPCE', 
    'dipole_moment', 'solvation_energy_eV', 'surface_area_A2', 'molecular_volume_A3'
]
missing_columns = [col for col in required_columns if col not in data.columns]
if missing_columns:
    raise ValueError(f"Missing required columns: {missing_columns}")

# Handle missing data for numeric columns only
numeric_columns = data.select_dtypes(include=[np.number]).columns
data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())

# Step 2: Calculate Descriptors
def calculate_descriptors(data, constants):
    data['deltaE_LCB'] = data['E_LUMO'] - constants['ECB_TiO2']
    data['deltaE_RedOxH'] = constants['Eredox_iodide'] - data['E_HOMO']
    data['deltaE_HL'] = data['E_LUMO'] - data['E_HOMO']
    data['IP'] = -data['E_HOMO']
    data['EA'] = -data['E_LUMO']
    data['elnChemPot'] = (-1 / 2) * (data['IP'] + data['EA'])
    data['chemHardness'] = (1 / 2) * (data['IP'] - data['EA'])
    data['electronegativity'] = -data['elnChemPot']
    data['electrophilicityIndex'] = data['elnChemPot'] ** 2 / data['chemHardness']
    data['electroacceptingPower'] = ((data['IP'] + 3 * data['EA']) ** 2) / (16 * (data['IP'] - data['EA']))
    data['electrodonatingPower'] = ((3 * data['IP'] + data['EA']) ** 2) / (16 * (data['IP'] - data['EA']))
    data['LHE'] = (1 - 10 ** -data['oscillator_strength']) * 100
    return data

data = calculate_descriptors(data, constants)

# Step 3: Define Features and Target for Training
features = [
    'deltaE_LCB', 'deltaE_RedOxH', 'deltaE_HL', 'IP', 'EA', 
    'elnChemPot', 'chemHardness', 'electronegativity', 
    'electrophilicityIndex', 'electroacceptingPower', 'electrodonatingPower', 'LHE', 
    'dipole_moment', 'solvation_energy_eV', 'surface_area_A2', 'molecular_volume_A3'
]
target = 'expPCE'  # Experimental PCE for training

X = data[features]
y = data[target]

# Step 4: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Track indices for labeling
train_indices = X_train.index
test_indices = X_test.index

# Step 5: Train a Random Forest Regressor and Extract Feature Importance
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Extract feature importance and normalize weights
feature_importance = rf_model.feature_importances_
total_importance = sum(feature_importance)
weights = {k: v / total_importance for k, v in dict(zip(features, feature_importance)).items()}
print("Estimated Feature Weights (Random Forest):", weights)

# Step 6: Calculate Weighted Scores for Rating (with added labels)
def calculate_weighted_scores(data, weights, train_indices, test_indices):
    score_columns = list(weights.keys())
    data['Weighted_Score'] = data[score_columns].mul(pd.Series(weights)).sum(axis=1)
    # Label dyes as Training or Testing
    data['Dataset_Label'] = 'Training'
    data.loc[test_indices, 'Dataset_Label'] = 'Testing'
    return data

data = calculate_weighted_scores(data, weights, train_indices, test_indices)

# Normalize Weighted Scores Relative to the Reference Dye (first dye)
reference_score = data.loc[0, 'Weighted_Score']
data['Normalized_Rating'] = (data['Weighted_Score'] / reference_score) * 100

# Assign Rankings
data['Ranking'] = data['Normalized_Rating'].rank(ascending=False).astype(int)

# Step 7: Save Results
output_file = "dyes_ranking_PBE_1.xlsx"
data.to_excel(output_file, index=False)

print(f"Ranking and rating results saved to: {output_file}")

# Optional: Visualize Feature Importance
plt.figure(figsize=(10, 6))
plt.barh(features, feature_importance)
plt.xlabel('Feature Importance')
plt.title('Random Forest Feature Importance')
plt.show()